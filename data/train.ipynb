{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde96104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision opencv-python albumentations matplotlib scikit-learn pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4da5de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import cv2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c6c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 416\n",
    "batch_size = 4\n",
    "NUM_CLASSES = 2 \n",
    "LEARNING_RATE = 0.001\n",
    "num_epochs = 50\n",
    "\n",
    "# Caminhos dos dados\n",
    "img_dir = 'all_dataset_images'  # Substitua pelo caminho das suas imagens\n",
    "label_dir = 'final_human_boat_dataset'  # Substitua pelo caminho das suas anotações\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d94dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanBoatDataset(Dataset):\n",
    "    def __init__(self, images_dir, labels_dir, img_size=640, transform=None):\n",
    "\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.labels_dir = Path(labels_dir)\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Listar todas as imagens\n",
    "        self.image_files = list(self.images_dir.glob('*.jpg'))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Carregar imagem\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Carregar anotações\n",
    "        label_path = self.labels_dir / f\"{img_path.stem}.txt\"\n",
    "        boxes = []\n",
    "        \n",
    "        if label_path.exists():\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    line = line.strip()\n",
    "                    if line:\n",
    "                        # Parse: class x_center y_center width height\n",
    "                        parts = line.split()\n",
    "                        if len(parts) == 5:\n",
    "                            class_id = int(parts[0])\n",
    "                            x_center = float(parts[1])\n",
    "                            y_center = float(parts[2])\n",
    "                            width = float(parts[3])\n",
    "                            height = float(parts[4])\n",
    "                            boxes.append([class_id, x_center, y_center, width, height])\n",
    "        \n",
    "        # Aplicar transformações na imagem\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Converter boxes para tensor\n",
    "        if boxes:\n",
    "            boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        else:\n",
    "            boxes = torch.zeros((0, 5), dtype=torch.float32)\n",
    "        \n",
    "        return image, boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "66164af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleYOLO(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SimpleYOLO, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Backbone simples (substitua por YOLOv5 backbone se necessário)\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((20, 20))  # Para 640x640 input\n",
    "        )\n",
    "        \n",
    "        # Head YOLO (5 = x,y,w,h,conf + num_classes)\n",
    "        self.head = nn.Conv2d(512, 3 * (5 + num_classes), 1)  # 3 anchors por grid\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d8f93d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YOLOLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        # Loss simplificada - implemente a loss completa do YOLO se necessário\n",
    "        # Por agora, retorna um valor constante para demonstração\n",
    "        return torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "605a0087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Função para tratar batches com número diferente de objetos por imagem\n",
    "    \"\"\"\n",
    "    images, targets = zip(*batch)\n",
    "    images = torch.stack(images)\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "22eeb5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do treinamento\n",
    "def setup_training(dataset_dir, batch_size=16, img_size=640, num_epochs=100):\n",
    "    \"\"\"\n",
    "    Configura o pipeline de treinamento\n",
    "    \"\"\"\n",
    "    \n",
    "    # Transformações\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Datasets\n",
    "    train_dataset = HumanBoatDataset(\n",
    "        images_dir=f\"{dataset_dir}/train/images\",\n",
    "        labels_dir=f\"{dataset_dir}/train/labels\",\n",
    "        img_size=img_size,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = HumanBoatDataset(\n",
    "        images_dir=f\"{dataset_dir}/val/images\",\n",
    "        labels_dir=f\"{dataset_dir}/val/labels\", \n",
    "        img_size=img_size,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False, \n",
    "        num_workers=4,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    # Modelo\n",
    "    model = SimpleYOLO(num_classes=2)  # 0: banhistas, 1: barcos\n",
    "    \n",
    "    # Loss e Optimizer\n",
    "    criterion = YOLOLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "    \n",
    "    # GPU se disponível\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    return model, train_loader, val_loader, criterion, optimizer, scheduler, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ac7dd896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Treina por uma época\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7eb03f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validação\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed5dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando device: cpu\n",
      "Dataset train: 2653 imagens\n",
      "Dataset val: 1048 imagens\n",
      "\n",
      "Epoch 1/50\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Configurações\n",
    "DATASET_DIR = \"dataset_yolo\"  # Pasta criada pelo script anterior\n",
    "BATCH_SIZE = 8\n",
    "IMG_SIZE = 640\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# Setup\n",
    "model, train_loader, val_loader, criterion, optimizer, scheduler, device = setup_training(\n",
    "    DATASET_DIR, BATCH_SIZE, IMG_SIZE, NUM_EPOCHS\n",
    ")\n",
    "\n",
    "print(f\"Usando device: {device}\")\n",
    "print(f\"Dataset train: {len(train_loader.dataset)} imagens\")\n",
    "print(f\"Dataset val: {len(val_loader.dataset)} imagens\")\n",
    "\n",
    "# Loop de treinamento\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Treinar\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validar\n",
    "    val_loss = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Salvar melhor modelo\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_yolo_model.pth')\n",
    "        print(\"Modelo salvo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5903355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
