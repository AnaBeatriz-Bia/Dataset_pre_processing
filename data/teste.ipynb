{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be6f3794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ NOTEBOOK DE TESTE R√ÅPIDO CARREGADO!\n",
      "========================================\n",
      "‚ö° EXECUTANDO TESTE ULTRA R√ÅPIDO...\n",
      "üìä 50 samples, 2 epochs, batch_size=2\n",
      "‚è±Ô∏è Tempo estimado: ~2 minutos\n",
      "‚ö° TESTE ULTRA R√ÅPIDO (50 samples, 2 epochs)\n",
      "üöÄ INICIANDO TESTE R√ÅPIDO DO PIPELINE\n",
      "==================================================\n",
      "\n",
      "1Ô∏è‚É£ Criando dataset de teste...\n",
      "üöÄ CRIANDO DATASET DE TESTE R√ÅPIDO\n",
      "========================================\n",
      "üìÅ Criando dataset de teste em: dataset_test\n",
      "üìä Amostras de treino: 40\n",
      "üìä Amostras de valida√ß√£o: 10\n",
      "--------------------------------------------------\n",
      "‚úÖ Train: 40 amostras copiadas\n",
      "‚úÖ Val: 10 amostras copiadas\n",
      "--------------------------------------------------\n",
      "‚úÖ Dataset de teste criado com sucesso!\n",
      "üìç Localiza√ß√£o: dataset_test\n",
      "\n",
      "üìä ESTAT√çSTICAS DO DATASET:\n",
      "------------------------------\n",
      "Train:  40 imagens,  40 labels\n",
      "  Val:  10 imagens,  10 labels\n",
      "------------------------------\n",
      "Total:  50 imagens,  50 labels\n",
      "\n",
      "üí° COMO USAR:\n",
      "1. Importe: from config import *\n",
      "2. Mude: DATASET_DIR = 'dataset_test'\n",
      "3. Execute seu treinamento normalmente!\n",
      "\n",
      "‚ö° Treinamento ser√° muito mais r√°pido para testes!\n",
      "\n",
      "2Ô∏è‚É£ Configurando dispositivo...\n",
      "‚úÖ Usando: cpu\n",
      "\n",
      "3Ô∏è‚É£ Criando DataLoaders...\n",
      "‚úÖ Train: 40 imagens\n",
      "‚úÖ Val: 10 imagens\n",
      "\n",
      "4Ô∏è‚É£ Criando modelo...\n",
      "‚úì Total de par√¢metros: 1,563,669\n",
      "‚úì Par√¢metros trein√°veis: 1,563,669\n",
      "‚úì Tamanho do modelo: 5.96 MB\n",
      "\n",
      "5Ô∏è‚É£ Testando forward pass...\n",
      "‚úÖ Input shape: torch.Size([2, 3, 640, 640])\n",
      "‚úÖ Output shape: torch.Size([2, 21, 20, 20])\n",
      "\n",
      "6Ô∏è‚É£ Executando treinamento de teste...\n",
      "‚è±Ô∏è √âpocas: 2\n",
      "üì¶ Batch size: 2\n",
      "------------------------------\n",
      "Device: cpu\n",
      "Dataset train: 40 imagens\n",
      "Dataset val: 10 imagens\n",
      "\n",
      "Epoch 1/2\n",
      "--------------------------------------------------\n",
      "Batch 0/20, Loss: 1.0000\n",
      "Batch 10/20, Loss: 1.0000\n",
      "Train Loss: 1.0000\n",
      "Val Loss: 1.0000\n",
      "Modelo salvo!\n",
      "\n",
      "Epoch 2/2\n",
      "--------------------------------------------------\n",
      "Batch 0/20, Loss: 1.0000\n",
      "Batch 10/20, Loss: 1.0000\n",
      "Train Loss: 1.0000\n",
      "Val Loss: 1.0000\n",
      "\n",
      "7Ô∏è‚É£ Testando infer√™ncia...\n",
      "‚úÖ Infer√™ncia OK: torch.Size([1, 21, 20, 20])\n",
      "\n",
      "==================================================\n",
      "üéâ TESTE R√ÅPIDO CONCLU√çDO COM SUCESSO!\n",
      "==================================================\n",
      "‚úÖ Pipeline funcionando corretamente\n",
      "‚úÖ Pronto para treinamento completo\n",
      "‚úÖ Modelo de teste salvo: test_model.pth\n",
      "\n",
      "üßπ Limpando dataset de teste...\n",
      "üóëÔ∏è Dataset de teste removido: dataset_test\n",
      "‚úÖ Teste ultra r√°pido conclu√≠do!\n",
      "üìÅ Criando dataset de teste personalizado...\n",
      "üöÄ CRIANDO DATASET DE TESTE R√ÅPIDO\n",
      "========================================\n",
      "üìÅ Criando dataset de teste em: dataset_test\n",
      "üìä Amostras de treino: 80\n",
      "üìä Amostras de valida√ß√£o: 20\n",
      "--------------------------------------------------\n",
      "‚úÖ Train: 80 amostras copiadas\n",
      "‚úÖ Val: 20 amostras copiadas\n",
      "--------------------------------------------------\n",
      "‚úÖ Dataset de teste criado com sucesso!\n",
      "üìç Localiza√ß√£o: dataset_test\n",
      "\n",
      "üìä ESTAT√çSTICAS DO DATASET:\n",
      "------------------------------\n",
      "Train:  80 imagens,  80 labels\n",
      "  Val:  20 imagens,  20 labels\n",
      "------------------------------\n",
      "Total: 100 imagens, 100 labels\n",
      "\n",
      "üí° COMO USAR:\n",
      "1. Importe: from config import *\n",
      "2. Mude: DATASET_DIR = 'dataset_test'\n",
      "3. Execute seu treinamento normalmente!\n",
      "\n",
      "‚ö° Treinamento ser√° muito mais r√°pido para testes!\n",
      "\n",
      "üìä ESTAT√çSTICAS DO DATASET:\n",
      "------------------------------\n",
      "Train:  80 imagens,  80 labels\n",
      "  Val:  20 imagens,  20 labels\n",
      "------------------------------\n",
      "Total: 100 imagens, 100 labels\n",
      "üîß Configura√ß√µes de teste: {'samples': 150, 'epochs': 8, 'batch_size': 6, 'learning_rate': 0.0005}\n",
      "üöÄ CRIANDO DATASET DE TESTE R√ÅPIDO\n",
      "========================================\n",
      "üìÅ Criando dataset de teste em: dataset_test\n",
      "üìä Amostras de treino: 120\n",
      "üìä Amostras de valida√ß√£o: 30\n",
      "--------------------------------------------------\n",
      "‚úÖ Train: 120 amostras copiadas\n",
      "‚úÖ Val: 30 amostras copiadas\n",
      "--------------------------------------------------\n",
      "‚úÖ Dataset de teste criado com sucesso!\n",
      "üìç Localiza√ß√£o: dataset_test\n",
      "\n",
      "üìä ESTAT√çSTICAS DO DATASET:\n",
      "------------------------------\n",
      "Train: 120 imagens, 120 labels\n",
      "  Val:  50 imagens,  50 labels\n",
      "------------------------------\n",
      "Total: 170 imagens, 170 labels\n",
      "\n",
      "üí° COMO USAR:\n",
      "1. Importe: from config import *\n",
      "2. Mude: DATASET_DIR = 'dataset_test'\n",
      "3. Execute seu treinamento normalmente!\n",
      "\n",
      "‚ö° Treinamento ser√° muito mais r√°pido para testes!\n",
      "‚úì Total de par√¢metros: 1,563,669\n",
      "‚úì Par√¢metros trein√°veis: 1,563,669\n",
      "‚úì Tamanho do modelo: 5.96 MB\n",
      "Device: cpu\n",
      "Dataset train: 120 imagens\n",
      "Dataset val: 50 imagens\n",
      "\n",
      "Epoch 1/8\n",
      "--------------------------------------------------\n",
      "Batch 0/20, Loss: 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     66\u001b[39m print_model_info(model)\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Treinamento\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m trained_model = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTEST_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mepochs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTEST_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlearning_rate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcustom_test_model.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     77\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Teste personalizado conclu√≠do!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# ===================================================================\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# C√âLULA 5: An√°lise dos resultados\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# ===================================================================\u001b[39;00m\n\u001b[32m     84\u001b[39m \n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Testar infer√™ncia com algumas imagens\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anabe\\.vscode\\github\\AFO_dataset_pre_processing\\data\\trainer.py:80\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, num_epochs, learning_rate, device, save_path)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# Treinar\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m train_loss = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Validar\u001b[39;00m\n\u001b[32m     83\u001b[39m val_loss = validate(model, val_loader, criterion, device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anabe\\.vscode\\github\\AFO_dataset_pre_processing\\data\\trainer.py:17\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, train_loader, criterion, optimizer, device)\u001b[39m\n\u001b[32m     14\u001b[39m images = images.to(device)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m loss = criterion(outputs, targets)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anabe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anabe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anabe\\.vscode\\github\\AFO_dataset_pre_processing\\data\\model.py:37\u001b[39m, in \u001b[36mSimpleYOLO.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.head(x)\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anabe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anabe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anabe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anabe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anabe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anabe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193\u001b[39m, in \u001b[36m_BatchNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    186\u001b[39m     bn_training = (\u001b[38;5;28mself\u001b[39m.running_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.running_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_mean\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anabe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\functional.py:2822\u001b[39m, in \u001b[36mbatch_norm\u001b[39m\u001b[34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[39m\n\u001b[32m   2819\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[32m   2820\u001b[39m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m.size())\n\u001b[32m-> \u001b[39m\u001b[32m2822\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2823\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2828\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2829\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2830\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2832\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset_sampler import create_quick_test_dataset, cleanup_test_dataset, show_dataset_stats\n",
    "from quick_test import run_quick_test, run_ultra_quick_test, run_medium_test\n",
    "\n",
    "print(\"üöÄ NOTEBOOK DE TESTE R√ÅPIDO CARREGADO!\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# ===================================================================\n",
    "# C√âLULA 2: Teste Ultra R√°pido (2 minutos)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"‚ö° EXECUTANDO TESTE ULTRA R√ÅPIDO...\")\n",
    "print(\"üìä 50 samples, 2 epochs, batch_size=2\")\n",
    "print(\"‚è±Ô∏è Tempo estimado: ~2 minutos\")\n",
    "\n",
    "# Executar teste ultra r√°pido\n",
    "model, dataset_dir = run_ultra_quick_test()\n",
    "\n",
    "print(\"‚úÖ Teste ultra r√°pido conclu√≠do!\")\n",
    "\n",
    "# ===================================================================\n",
    "# C√âLULA 3: Criar dataset de teste personalizado\n",
    "# ===================================================================\n",
    "\n",
    "# Op√ß√£o 1: Dataset pequeno para debug\n",
    "print(\"üìÅ Criando dataset de teste personalizado...\")\n",
    "\n",
    "# Criar dataset com 100 imagens\n",
    "test_dataset = create_quick_test_dataset(samples=100)\n",
    "show_dataset_stats(test_dataset)\n",
    "\n",
    "# ===================================================================\n",
    "# C√âLULA 4: Teste com configura√ß√µes personalizadas\n",
    "# ===================================================================\n",
    "\n",
    "from config import *\n",
    "from dataset import create_dataloaders\n",
    "from model import create_model\n",
    "from trainer import train_model\n",
    "from utils import get_device, print_model_info\n",
    "\n",
    "# Configura√ß√µes de teste\n",
    "TEST_CONFIG = {\n",
    "    'samples': 150,\n",
    "    'epochs': 8,\n",
    "    'batch_size': 6,\n",
    "    'learning_rate': 0.0005\n",
    "}\n",
    "\n",
    "print(f\"üîß Configura√ß√µes de teste: {TEST_CONFIG}\")\n",
    "\n",
    "# Criar dataset de teste\n",
    "test_dir = create_quick_test_dataset(samples=TEST_CONFIG['samples'])\n",
    "\n",
    "# Setup\n",
    "device = get_device()\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    dataset_dir=test_dir,\n",
    "    batch_size=TEST_CONFIG['batch_size'],\n",
    "    img_size=IMG_SIZE,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "model = create_model(num_classes=NUM_CLASSES, device=device)\n",
    "print_model_info(model)\n",
    "\n",
    "# Treinamento\n",
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=TEST_CONFIG['epochs'],\n",
    "    learning_rate=TEST_CONFIG['learning_rate'],\n",
    "    device=device,\n",
    "    save_path='custom_test_model.pth'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Teste personalizado conclu√≠do!\")\n",
    "\n",
    "# ===================================================================\n",
    "# C√âLULA 5: An√°lise dos resultados\n",
    "# ===================================================================\n",
    "\n",
    "# Testar infer√™ncia com algumas imagens\n",
    "trained_model.eval()\n",
    "\n",
    "# Pegar um batch de teste\n",
    "sample_batch = next(iter(val_loader))\n",
    "images, targets = sample_batch\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = trained_model(images.to(device))\n",
    "    \n",
    "print(f\"üìä An√°lise dos resultados:\")\n",
    "print(f\"   Input shape: {images.shape}\")\n",
    "print(f\"   Predictions shape: {predictions.shape}\")\n",
    "print(f\"   N√∫mero de targets: {len(targets)}\")\n",
    "\n",
    "# Visualizar uma imagem (opcional)\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Desnormalizar imagem para visualiza√ß√£o\n",
    "def denormalize(tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    return tensor * std + mean\n",
    "\n",
    "# Mostrar primeira imagem\n",
    "img = denormalize(images[0]).permute(1, 2, 0).numpy()\n",
    "img = np.clip(img, 0, 1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img)\n",
    "plt.title(\"Imagem de Teste\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# ===================================================================\n",
    "# C√âLULA 6: Compara√ß√£o de velocidade\n",
    "# ===================================================================\n",
    "\n",
    "import time\n",
    "\n",
    "def benchmark_inference(model, dataloader, device, num_batches=10):\n",
    "    \"\"\"Mede velocidade de infer√™ncia\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for i, (images, _) in enumerate(dataloader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "                \n",
    "            start_time = time.time()\n",
    "            _ = model(images.to(device))\n",
    "            end_time = time.time()\n",
    "            \n",
    "            times.append(end_time - start_time)\n",
    "    \n",
    "    avg_time = sum(times) / len(times)\n",
    "    fps = images.size(0) / avg_time  # frames per second\n",
    "    \n",
    "    return avg_time, fps\n",
    "\n",
    "# Benchmark do modelo\n",
    "avg_time, fps = benchmark_inference(trained_model, val_loader, device)\n",
    "\n",
    "print(f\"‚ö° BENCHMARK DE PERFORMANCE:\")\n",
    "print(f\"   Tempo m√©dio por batch: {avg_time:.4f}s\")\n",
    "print(f\"   FPS (frames per second): {fps:.2f}\")\n",
    "print(f\"   Batch size: {TEST_CONFIG['batch_size']}\")\n",
    "\n",
    "# ===================================================================\n",
    "# C√âLULA 7: Limpeza (opcional)\n",
    "# ===================================================================\n",
    "\n",
    "# Descomente para limpar os datasets de teste\n",
    "\"\"\"\n",
    "cleanup_test_dataset(test_dataset)\n",
    "cleanup_test_dataset(test_dir)\n",
    "print(\"üßπ Datasets de teste removidos!\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéâ TODOS OS TESTES CONCLU√çDOS!\")\n",
    "print(\"=\"*50)\n",
    "print(\"‚úÖ Pipeline funcionando corretamente\")\n",
    "print(\"‚úÖ Pronto para treinamento completo\")\n",
    "print(\"üí° Para treinamento completo, use: %run main.py\")\n",
    "\n",
    "# ===================================================================\n",
    "# C√âLULA 8: Fun√ß√µes utilit√°rias para testes r√°pidos\n",
    "# ===================================================================\n",
    "\n",
    "def quick_debug_test():\n",
    "    \"\"\"Teste super r√°pido para debug\"\"\"\n",
    "    print(\"üêõ TESTE DE DEBUG (20 samples, 1 epoch)\")\n",
    "    return run_quick_test(samples=20, epochs=1, batch_size=2)\n",
    "\n",
    "def validate_pipeline():\n",
    "    \"\"\"Valida se o pipeline est√° funcionando\"\"\"\n",
    "    try:\n",
    "        quick_debug_test()\n",
    "        print(\"‚úÖ Pipeline validado com sucesso!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro na valida√ß√£o: {e}\")\n",
    "        return False\n",
    "\n",
    "def memory_test():\n",
    "    \"\"\"Testa uso de mem√≥ria\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"üîã Mem√≥ria GPU antes: {torch.cuda.memory_allocated()//1024//1024}MB\")\n",
    "        \n",
    "        # Criar modelo tempor√°rio\n",
    "        temp_model = create_model(device='cuda')\n",
    "        temp_images = torch.randn(4, 3, IMG_SIZE, IMG_SIZE).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _ = temp_model(temp_images)\n",
    "        \n",
    "        print(f\"üîã Mem√≥ria GPU depois: {torch.cuda.memory_allocated()//1024//1024}MB\")\n",
    "        \n",
    "        # Limpeza\n",
    "        del temp_model, temp_images\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        print(f\"üîã Mem√≥ria GPU ap√≥s limpeza: {torch.cuda.memory_allocated()//1024//1024}MB\")\n",
    "    else:\n",
    "        print(\"üíª Usando CPU - teste de mem√≥ria n√£o aplic√°vel\")\n",
    "\n",
    "# Executar valida√ß√£o\n",
    "print(\"\\nüîç VALIDANDO PIPELINE...\")\n",
    "pipeline_ok = validate_pipeline()\n",
    "\n",
    "if pipeline_ok:\n",
    "    print(\"üéØ Pronto para come√ßar o desenvolvimento!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Verifique os erros antes de continuar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f33aad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
